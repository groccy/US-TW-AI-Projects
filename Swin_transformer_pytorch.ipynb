{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swin Transformers in PyTorch\n",
    "\n",
    "This notebook trains a  Vision Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T # for simplifying the transforms\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, sampler, random_split\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Now, we import timm, torchvision image models\n",
    "# !pip install timm # kaggle doesnt have it installed by default\n",
    "import timm\n",
    "from timm.loss import LabelSmoothingCrossEntropy # This is better than normal nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_classes(data_dir):\n",
    "    all_data = datasets.ImageFolder(data_dir)\n",
    "    return all_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_loaders(data_dir, batch_size, train = False):\n",
    "    if train:\n",
    "        #train\n",
    "        transform = T.Compose([\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomVerticalFlip(),\n",
    "            T.RandomApply(torch.nn.ModuleList([T.ColorJitter()]), p=0.25),\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(timm.data.IMAGENET_DEFAULT_MEAN, timm.data.IMAGENET_DEFAULT_STD), # imagenet means\n",
    "            T.RandomErasing(p=0.1, value='random')\n",
    "        ])\n",
    "        train_data = datasets.ImageFolder(os.path.join(data_dir, \"training/\"), transform = transform)\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "        return train_loader, len(train_data)\n",
    "    else:\n",
    "        # val/test\n",
    "        transform = T.Compose([ # We dont need augmentation for test transforms\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(timm.data.IMAGENET_DEFAULT_MEAN, timm.data.IMAGENET_DEFAULT_STD), # imagenet means\n",
    "        ])\n",
    "        val_data = datasets.ImageFolder(os.path.join(data_dir, \"validation/\"), transform=transform) ## remove validation\n",
    "        test_data = datasets.ImageFolder(os.path.join(data_dir, \"testing/\"), transform=transform)\n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=4) ## remove validation\n",
    "        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "        return test_loader, val_loader, len(test_data), len(val_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = \"C:\\\\Users\\\\Sandisk\\\\Documents\\\\Python Scripts\\\\BICS6_ML\\\\Swing Transformer\\\\patch5_diff_split\"\n",
    "\n",
    "# dataset_path = \"/kaggle/input/butterfly-images40-species/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train_loader, train_data_len) = get_data_loaders(dataset_path, 128, train=True)\n",
    "# (test_loader, test_data_len) = get_data_loaders(dataset_path, 32, train=False)\n",
    "(val_loader, test_loader, valid_data_len, test_data_len) = get_data_loaders(dataset_path, 32, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '41', '43', '97', '98', '99'] 7\n"
     ]
    }
   ],
   "source": [
    "classes = get_classes(\"C:\\\\Users\\\\Sandisk\\\\Documents\\\\Python Scripts\\\\BICS6_ML\\\\Swing Transformer\\\\patch5_diff_split\\\\training\") #get_classes(\"/kaggle/input/butterfly-images40-species/train/\")\n",
    "print(classes, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    \"train\": train_loader,\n",
    "    \"val\": val_loader\n",
    "}\n",
    "dataset_sizes = {\n",
    "    \"train\": train_data_len,\n",
    "    \"val\": valid_data_len\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 12 5\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1390 363 159\n"
     ]
    }
   ],
   "source": [
    "print(train_data_len, valid_data_len, test_data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, for the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Sandisk/.cache\\torch\\hub\\SharanSMenon_swin-transformer-hub_main\n"
     ]
    }
   ],
   "source": [
    "HUB_URL = \"SharanSMenon/swin-transformer-hub:main\"\n",
    "MODEL_NAME = \"swin_tiny_patch4_window7_224\"\n",
    "# check hubconf for more models.\n",
    "model = torch.hub.load(HUB_URL, MODEL_NAME, pretrained=True) # load from torch hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.3, inplace=False)\n",
      "  (3): Linear(in_features=512, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters(): #freeze model\n",
    "    param.requires_grad = False\n",
    "\n",
    "n_inputs = model.head.in_features\n",
    "model.head = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, len(classes))\n",
    ")\n",
    "model = model.to(device)\n",
    "print(model.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = LabelSmoothingCrossEntropy()\n",
    "criterion = criterion.to(device)\n",
    "optimizer = optim.AdamW(model.head.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lr scheduler\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print(\"-\"*10)\n",
    "        \n",
    "        for phase in ['train', 'val']: # We do training and validation phase per epoch\n",
    "            if phase == 'train':\n",
    "                model.train() # model to training mode\n",
    "            else:\n",
    "                model.eval() # model to evaluate\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "            \n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'): # no autograd makes validation go faster\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1) # used for accuracy\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step() # step at end of epoch\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc =  running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict()) # keep the best validation accuracy model\n",
    "        print()\n",
    "    time_elapsed = time.time() - since # slight error\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print(\"Best Val Acc: {:.4f}\".format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/6\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:11<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.3990 Acc: 0.5698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0932 Acc: 0.6970\n",
      "\n",
      "Epoch 1/6\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:11<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.1039 Acc: 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9739 Acc: 0.7631\n",
      "\n",
      "Epoch 2/6\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:11<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0178 Acc: 0.7468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9503 Acc: 0.7824\n",
      "\n",
      "Epoch 3/6\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9892 Acc: 0.7568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9238 Acc: 0.8044\n",
      "\n",
      "Epoch 4/6\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9592 Acc: 0.7662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9010 Acc: 0.7961\n",
      "\n",
      "Epoch 5/6\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:11<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9474 Acc: 0.7770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.8848 Acc: 0.8209\n",
      "\n",
      "Epoch 6/6\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:11<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9263 Acc: 0.7935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.8898 Acc: 0.8072\n",
      "\n",
      "Training complete in 1m 49s\n",
      "Best Val Acc: 0.8209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=7) # now it is a lot faster num_epochs = 7\n",
    "# I will come back after 10 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing\n",
    "\n",
    "Ok, now we finished training. Lets run the dataset on the test loader and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1589\n",
      "Test Accuracy of     1: 100% (51/51)\n",
      "Test Accuracy of     2: 93% (28/30)\n",
      "Test Accuracy of    41:  0% ( 0/ 8)\n",
      "Test Accuracy of    43: 16% ( 1/ 6)\n",
      "Test Accuracy of    97:  0% ( 0/ 3)\n",
      "Test Accuracy of    98: 20% ( 1/ 5)\n",
      "Test Accuracy of    99: 96% (24/25)\n",
      "Test Accuracy of 82% (105/128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "class_correct = list(0 for i in range(len(classes)))\n",
    "class_total = list(0 for i in range(len(classes)))\n",
    "model_ft.eval()\n",
    "\n",
    "for data, target in tqdm(test_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    with torch.no_grad(): # turn off autograd for faster testing\n",
    "        output = model_ft(data)\n",
    "        loss = criterion(output, target)\n",
    "    test_loss = loss.item() * data.size(0)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    if len(target) == 32:\n",
    "        for i in range(32):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "test_loss = test_loss / test_data_len\n",
    "print('Test Loss: {:.4f}'.format(test_loss))\n",
    "for i in range(len(classes)):\n",
    "    if class_total[i] > 0:\n",
    "        print(\"Test Accuracy of %5s: %2d%% (%2d/%2d)\" % (\n",
    "            classes[i], 100*class_correct[i]/class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])\n",
    "        ))\n",
    "    else:\n",
    "        print(\"Test accuracy of %5s: NA\" % (classes[i]))\n",
    "print(\"Test Accuracy of %2d%% (%2d/%2d)\" % (\n",
    "            100*np.sum(class_correct)/np.sum(class_total), np.sum(class_correct), np.sum(class_total)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0.0\n",
    "class_correct = list(0 for i in range(len(classes)))\n",
    "class_total = list(0 for i in range(len(classes)))\n",
    "model_ft.eval()\n",
    "\n",
    "for data, target in tqdm(test_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    with torch.no_grad(): # turn off autograd for faster testing\n",
    "        output = model_ft(data)\n",
    "        loss = criterion(output, target)\n",
    "    test_loss = loss.item() * data.size(0)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    if len(target) == 32:\n",
    "        for i in range(32):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "test_loss = test_loss / test_data_len\n",
    "print('Test Loss: {:.4f}'.format(test_loss))\n",
    "for i in range(len(classes)):\n",
    "    if class_total[i] > 0:\n",
    "        print(\"Test Accuracy of %5s: %2d%% (%2d/%2d)\" % (\n",
    "            classes[i], 100*class_correct[i]/class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])\n",
    "        ))\n",
    "    else:\n",
    "        print(\"Test accuracy of %5s: NA\" % (classes[i]))\n",
    "print(\"Test Accuracy of %2d%% (%2d/%2d)\" % (\n",
    "            100*np.sum(class_correct)/np.sum(class_total), np.sum(class_correct), np.sum(class_total)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# our model earns 93% test accuracy, which is very high. lets save it\n",
    "example = torch.rand(1, 3, 224, 224)\n",
    "traced_script_module = torch.jit.trace(model.cpu(), example)\n",
    "traced_script_module.save(\"swin_transformer_patch_image_82pct.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's it for this video, see you next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51, 28, 0, 1, 0, 1, 24]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51, 30, 8, 6, 3, 5, 25]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[67.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 2., 33.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 3.,  6.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 1.,  6.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  2.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 4.,  1.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0., 29.]])\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 7\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "\n",
    "for data, target in tqdm(test_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    with torch.no_grad(): # turn off autograd for faster testing\n",
    "        output = model_ft(data)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    for t, p in zip(target.view(-1), preds.view(-1)):\n",
    "            confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for i, (inputs, classes) in enumerate(test_loader):\n",
    "#         # inputs = inputs.to(device)\n",
    "#         classes = classes.to(device)\n",
    "#         outputs = model_ft(inputs)\n",
    "#         _, preds = torch.max(outputs, 1)\n",
    "#         for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "#                 confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|████████████████▊                                                                   | 1/5 [00:04<00:17,  4.34s/it]\u001b[A\n",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:06<00:09,  3.03s/it]\u001b[A\n",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:08<00:05,  2.62s/it]\u001b[A\n",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:10<00:02,  2.42s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:13<00:00,  2.61s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 69.0, 'Predicted label')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "nb_classes = 7\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "\n",
    "for data, target in tqdm(test_loader):\n",
    "    data, target = data, target.to(device)\n",
    "# for data in tqdm(test_loader):\n",
    "    # data, target = data, target.to(device)\n",
    "    with torch.no_grad(): # turn off autograd for faster testing\n",
    "        model_ft = torch.load(\"swin_transformer_patch_image_82pct.pt\")\n",
    "        model_ft.eval()\n",
    "        output = model_ft(data)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "            confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for i, (inputs, classes) in enumerate(test_loader):\n",
    "#         # inputs = inputs.to(device)\n",
    "#         classes = classes.to(device)\n",
    "#         outputs = model_ft(inputs)\n",
    "#         _, preds = torch.max(outputs, 1)\n",
    "#         for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "#                 confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "class_names = ['1', '2', '41', '43', '97', '98', '99'] #list(label2class.values())\n",
    "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
    "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4375, 0.3714, 0.0000, 0.0000, 0.0000, 0.0000, 0.1379])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
